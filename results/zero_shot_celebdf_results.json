{
  "qwen_vl": {
    "model": "qwen_vl",
    "model_full_name": "Qwen2-VL-2B",
    "dataset": "celebdf",
    "prompt_type": "zero_shot_binary",
    "num_samples": 200,
    "metrics": {
      "accuracy": 0.335,
      "precision": 0.88,
      "recall": 0.2573099415204678,
      "f1": 0.39819004524886875,
      "valid_ratio": 1.0,
      "auc": 0.525206694898165
    },
    "per_manipulation": {
      "deepfake": {
        "accuracy": 0.2573099415204678,
        "precision": 1.0,
        "recall": 0.2573099415204678,
        "f1": 0.40930232558139534,
        "valid_ratio": 1.0,
        "auc": 0.0,
        "count": 171
      },
      "real": {
        "accuracy": 0.7931034482758621,
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "valid_ratio": 1.0,
        "auc": 0.0,
        "count": 29
      }
    },
    "predictions_summary": {
      "total": 200,
      "valid": 200,
      "predicted_fake": 50,
      "predicted_real": 150
    }
  },
  "phi3_vision": {
    "error": "FlashAttention2 has been toggled on, but it cannot be used due to the following error: the package flash_attn seems to be not installed. Please refer to the documentation of https://huggingface.co/docs/transformers/perf_infer_gpu_one#flashattention-2 to install Flash Attention 2."
  },
  "moondream": {
    "model": "moondream",
    "model_full_name": "MoonDream2",
    "dataset": "celebdf",
    "prompt_type": "zero_shot_binary",
    "num_samples": 200,
    "metrics": {
      "accuracy": 0.335,
      "precision": 0.9130434782608695,
      "recall": 0.24561403508771928,
      "f1": 0.3870967741935484,
      "valid_ratio": 1.0,
      "auc": 0.544162129461585
    },
    "per_manipulation": {
      "deepfake": {
        "accuracy": 0.24561403508771928,
        "precision": 1.0,
        "recall": 0.24561403508771928,
        "f1": 0.39436619718309857,
        "valid_ratio": 1.0,
        "auc": 0.0,
        "count": 171
      },
      "real": {
        "accuracy": 0.8620689655172413,
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "valid_ratio": 1.0,
        "auc": 0.0,
        "count": 29
      }
    },
    "predictions_summary": {
      "total": 200,
      "valid": 200,
      "predicted_fake": 46,
      "predicted_real": 154
    }
  },
  "internvl": {
    "error": "'Phi3ForCausalLM' object has no attribute 'generate'"
  },
  "llava_next": {
    "model": "llava_next",
    "model_full_name": "LLaVA-NeXT-7B",
    "dataset": "celebdf",
    "prompt_type": "zero_shot_binary",
    "num_samples": 200,
    "metrics": {
      "accuracy": 0.85,
      "precision": 0.8542713567839196,
      "recall": 0.9941520467836257,
      "f1": 0.918918918918919,
      "valid_ratio": 1.0,
      "auc": 0.49707602339181284
    },
    "per_manipulation": {
      "deepfake": {
        "accuracy": 0.9941520467836257,
        "precision": 1.0,
        "recall": 0.9941520467836257,
        "f1": 0.9970674486803519,
        "valid_ratio": 1.0,
        "auc": 0.0,
        "count": 171
      },
      "real": {
        "accuracy": 0.0,
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "valid_ratio": 1.0,
        "auc": 0.0,
        "count": 29
      }
    },
    "predictions_summary": {
      "total": 200,
      "valid": 200,
      "predicted_fake": 199,
      "predicted_real": 1
    }
  }
}